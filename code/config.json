{
  "model":  {
    "type": "MLP",
    "name": "model_mlp_relu",
    "num_hidden_layers":  1,
    "num_hidden_units": [20],
    "activation": "ReLU",
    "loss": "CrossEntropy"
  },
  "num_epochs": 2,
  "batch_size": 100,
  "save_dir":  null,
  "log_file": null,
  "learning_rate": 0.001,
  "weight_decay": 0.03,
  "normalize":  true,
  "show_plot": true,
  "print_acc":  false
}